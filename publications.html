<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width">
    <meta name="description" content="Suhas Shivaprakash">
    <meta name="keywords" content="Suhas Shivaprakash, Mixed Circuit VLSI Design
,neural networks, Shivapakash">
    <meta name="Suhas Shivapakash" content="Shiva Shivapakash">
    <title>Suhas Shivaprakash | Publication</title>
   <!-- <link rel="stylesheet" href="./css/style.css">-->
      
   <style>   
      body{
  font: 15px/1.5 Arial, Helvetica,sans-serif;
  padding:0;
  margin:0;
  background-color:#f4f4f4;
}

/* Global */
.container{
  width:80%;
  margin:auto;
  overflow:hidden;
}

ul{
  margin:0;
  padding:0;
}

/* Header **/
header{
  background-color:deepskyblue;
  color:#ffffff;
  padding-top:30px;
  min-height:70px;
  border-bottom:#f4f4f4 10px solid;
}

header a{
  color:darkblue;
  text-decoration:none;
  text-transform: uppercase;
  font-size:16px;
}

header li{
  float:left;
  display:inline;
  padding: 0 20px 0 20px;
}

header #branding{
  float:left;
}

header #branding h1{
  margin:0;
}

header nav{
  float:right;
  margin-top:10px;
}

header .highlight, header .current a{
  color:white;
  font-weight:bold;
}

header a:hover{
  color:black;
  font-weight:bold;
}

        a {
  text-decoration: none;
            color: deepskyblue;
}

footer{
  padding:20px;
  margin-top:20px;
  color:black;
  background-color:deepskyblue;
  text-align: center;
}

  }
}
      </style>

  </head>
  <body>
    <header>
      <div class="container">
        <div id="branding">
            <h1><a href="index.html"><span style="color: white;font-size: 20px; padding-bottom: -10px;">Suhas Shivapakash</span></a></h1>
        </div>
        <nav>
          <ul>
            <li><a href="index.html">About me</a></li>
            <li><a href="latestupdate.html">Latest updates</a></li>
            <li><a href="professionalexperience.html">Professional experience</a></li>
              <li class="current"><a href="publications.html">Publications</a></li>
              <li><a href="project.html">Projects</a></li>
              <li><a href="contactme.html">Contact me</a></li>
          </ul>
        </nav>
      </div>
    </header>
    <section id="showcase">
      <div class="container">
      </div>
    </section>
      <h2 style="text-align: center; padding: inherit; padding-left: 5%;">A Power Efficient Multi-Bit Accelerator for Memory Prohibitive Deep Neural Networks
<a href="https://iscas2020.org/">IEEE International Symposium on Circuits and Systems (ISCAS), Spain, 2020</a>
<a href="index.html">Suhas Shivapakash,</a>
<a href="https://www.cv.tu-berlin.de/menue/mitarbeiter/hardik_jain/">Hardik Jain,</a>
<a href="https://www.cv.tu-berlin.de/menue/mitarbeiter/olaf_hellwich/"> Olaf Hellwich,</a>
<a href="https://www.msc.tu-berlin.de/menue/team/gerfers_eng/">Friedel Gerfers</a></h2>
      <img src="img/Power_Architecture.jpg" style="width:90% ;height:90%; padding-left: 5%;">
      <p style="text-align: center; padding: inherit; font-size: 15px; padding-left: 5%;">State of art deep neural network (DNN) models are both memory prohibitive and computationally intensive with millions of connections. Employing these models for an embedded mobile application is resource limited with large amount of power consumption and significant bandwidth requirement (to access the data from the external DRAM). In a custom FPGA hardware the bandwidth access from the DRAM is two to three times higher, compared to the MAC (Multiply-Accumulate) operation. In this paper, we propose a power efficient multi-bit neural network accelerator, where we employ the technique of truncating the partial sum (PSum) results from the previous layer before feeding it into the next layer. We demonstrate that, using our multi-bit accelerator, accuracy is maintained upto bit width of 12. The proposed truncation scheme has 50% power reduction and resource utilization was reduced by 16% for LUTs (Look-up tables), 9% for FFs (Flip-Flops), 19% for BRAMs (Block RAMs) and 7% for Digital Signal Processors (DSPs) when compared with the 32 bits architecture. A large network, AlexNet was used as a benchmark DNN model and Kintex-7 KC705 FPGA was used to test the architecture. <a href="https://www.epapers.org/iscas2020/ESR/paper_details.php?PHPSESSID=ahot32rct1i70mbiumrnkf5633&paper_id=1484" target="_blank">Find out more</a> 
<hr>
      <h2 style="text-align: center; padding: inherit; padding-left: 5%;">Comparison of Hsclone and Roulette Genetic Algorithms on the Application of Combinational Circuits
<a href="https://www.ijeat.org/">International Journal of Engineering and Advanced Technology (IJEAT), ISSN: 2249 – 8958, Volume-5, Issue-4, April 2016</a>
Suhas Shivapakash,<a href="https://www.linkedin.com/in/unavailable/"> Rajini V H ,</a><a href="https://www.linkedin.com/in/gayatri-malhotra-bb3b5622/"> Gayatri Malhotra</a></h2>
      <img src="img/Genetic_Algorithms.jpg" style="width:90%;height:90%px; padding-left: 5%; ">
      <p style="text-align: center; padding: inherit; padding-left: 5%;">Future planetary and deep space exploration require robust methods of operation to operate spacecraft in the outer atmosphere without any variations or faults. The best fault tolerant method which can be used for operations of this kind is the class of Genetic Algorithms (GA) which are a sort of evolutionary algorithm. In this domain of operation, a combinational circuit is designed by the method of Cartesian Genetic Programming (CGP). The Circuit after the design is fed to the two GAs, namely, HsClone and Roulette. The main advantage in this use of GA is the likely determination of the best possible circuit within the space of a thousand circuits. The combinational circuit design is applied to both the algorithms and tested for fitness. After the required fitness is obtained, both the algorithms are compared with respect to their cumulative generational fitness and other allied aspects. The better algorithm will hence be determined to integrate it into the future design of spacecraft hardware. This is expected to help the spacecraft recover from Single Event Upsets (SEU) which usually occur due to hostile temperature conditions and outer atmospheric radiation. <a href="https://www.semanticscholar.org/404" target="_blank">Find out more</a></p>
<hr>
        <h2 style="text-align: center; padding: inherit; padding-left: 5%;">A 9-bit, 45mW, 0.05mm2 Source-Series-Terminated DAC Driver with Echo Canceller in 22nm CMOS for In-Vehicle Communication,
publication date January 1 2021 
            <a href="https://www.linkedin.com/in/hossein-ghafarian-102a6a5a/">Hossein Ghafarian, </a><a href="https://www.linkedin.com/in/nima-lotfi-b6a81844/"> Nima Lotfi,</a>
            <a href="#">Philipp Scholz, </a>
            <a href="https://www.msc.tu-berlin.de/menue/team/gerfers_eng/"> Friedel Gerfers</a>
            </h2>
      <p style="align-content: center; padding: inherit; padding-left: 5%;">This work presents an SST 9-bit TX-DAC driver, that is fully compliant to the new Automotive Ethernet (AE) Standard IEEE P802.3ch. The TX driver design incorporates a highly-correlated timing-matched 9-bit echo DAC canceler (EC-DAC) to eliminate up-to 24.4dB of the transmit power from RX path, due to full duplex transmission scheme. The TX-EC-DAC driver combination inherently provides 100Ω differential termination and possesses a PVT calibration scheme covering up to 3 sigma process variation with a resolution of 2.5Ω. Designed and fabricated in a 22nm FD-SOI technology, the TX-DAC enables a 1Vppd PAM4 signal swing with raw data rates up to 11.2Gb/s and Nyquist tone sine wave linearity SFDR of better than 54.4dBFS thanks to the supply degeneration approach. The driver pair is backward compatible to all relevant AE Standards 10/5/2.5/1GBase-T1 and occupies the smallest area of only 0.05mm2. The 9-bit TX-EC-DAC combination dissipates 3/42mW from dual 0.8/1.2V power supply with a power efficiency of 2mW/Gb/s per DAC.<a href="https://ieeexplore.ieee.org/document/9312144" target="_blank"> Find out more</a></p>
<hr>
      <h2 style="text-align: center; padding: inherit; padding-left: 5%;">FantastIC4: A Hardware-Software Co-Design Approach for Efficiently Running 4bit-Compact Multilayer Perceptrons
publication dateDec 12, 2020  publication descriptionArXiV 
            <a href="https://www.linkedin.com/in/hossein-ghafarian-102a6a5a/">Simon Wiedemann,</a><a href="index.html"> Suhas Shivapakash,</a>
            <a href="#">Pablo Wiedemann,</a>
            <a href="#">  Daniel Becking, </a>
         <a href="https://www.linkedin.com/in/wojciech-samek-78336a157/"> Wojciech Samek, </a>
          <a href="https://www.msc.tu-berlin.de/menue/team/gerfers_eng/"> Friedel Gerfers, </a>
          <a href="#"> Thomas Wiegand</a>
            </h2>
      <p style="align-content: center; padding: inherit; padding-left: 5%;">IEEE open journal circuits and system is under review. Abstract is from pre-print of ArXiV<br>With the growing demand for deploying deep learning models to the “edge”, it is paramount to develop techniques that allow to execute state-of-the-art models within very tight and limited resource constraints. In this work we propose a software-hardware optimization paradigm for obtaining a highly efficient execution engine of deep neural networks (DNNs) that are based on fully-connected layers. Our approach is centred around compression as a means for reducing the area as well as power requirements of, concretely, multilayer perceptrons (MLPs) with high predictive performances. Firstly, we design
a novel hardware architecture named FantastIC4, which (1) supports the efficient on-chip execution of multiple compact representations of fully-connected layers and (2) minimizes the required number of multipliers for inference down to only 4 (thus the name). Moreover, in order to make the models amenable for efficient execution on FantastIC4, we introduce a novel entropyconstrained training method that renders them to be robust to 4bit quantization and highly compressible in size simultaneously. The experimental results show that we can achieve throughputs of 2.45 TOPS with a total power consumption of 3.6W on a Virtual Ultrascale FPGA XCVU440 device implementation, and achieve a total power efficiency of 20.17 TOPS/W on a 22nm process ASIC version. When compared to the other state-of-theart accelerators designed for the Google Speech Command (GSC) dataset, FantastIC4 is better by 51× in terms of throughput and 145× in terms of area efficiency (GOPS/W).<a href="https://arxiv.org/pdf/2012.11331.pdf" target="_blank"> Find out more</a></p>
      <hr>
  
      <h2 style="text-align: center; padding: inherit; padding-left: 5%;">A Power Efficient Multi-Bit Accelerator for Memory Prohibitive Deep Neural Networks
          <a href="index.html">Suhas Shivapakash,</a>
          <a href="https://www.cv.tu-berlin.de/menue/mitarbeiter/hardik_jain/">Hardik Jain,</a>
          <a href="https://www.cv.tu-berlin.de/menue/mitarbeiter/olaf_hellwich/"> Olaf Hellwich,</a>
          <a href="https://www.msc.tu-berlin.de/menue/team/gerfers_eng/">Friedel Gerfers</a></h2>
      <p style="text-align: center; padding: inherit; font-size: 15px; padding-left: 5%;">IEEE Open Journal Circuits and Sytems

publication descriptionPaper is accepted and yet to publsihed in IEEE. The DOI is 10.1109/OJCAS.2020.3047225
<hr>
            
      <h1 style="text-align: center; padding-left: 5%;">Master's Thesis</h1>
     <p style="text-align: center; padding: inherit;"><h2 style="align-content: center; padding:inherit;padding-left: 5%;">Implementation of genetic algorithms on ultra scale FPGAs to avoid single-event upset on deep space missions<a href="https://vtu.ac.in/">Visvesvaraya Technological University,</a><a href="https://www.isro.gov.in/about-isro/u-r-rao-satellite-centre-ursc">ISRO Satellite Centre May 2016</a>
      <br></h2>
      <img src="img/Genetic_Algorithm.jpg" style="width:90%;height:90%; padding-left: 5%;">
<p style="align-content: center; padding: inherit; padding-left: 5%;">Deep space research and planetary exploration requires that the space vehicles should have robust system and reconfigurable architecture in the unpredictable environment. During this scenario there is a drastic need to develop a hardware architecture that can provide evolved hardware architecture in deep space environment, for this reason we will develop an evolutionary design of electronic circuits or an evolvable hardware that allows the On-Board Computer (OBC) to automatically obtain the desired circuit design configuration. This Evolvable Hardware technology that is developed will help to maintain the functionality of the design even in the presence of faults and degradation due to ageing, temperature and radiation. The key benefits are spacecraft survivability, to carry out new mission requirements, adaptation to new mission requirements and mission reliability. This Evolvable Hardware technology also helps in interplanetary mission taken by the space agency. The entire circuit configuration uses Evolutionary Algorithm, where one such algorithm is the Genetic Algorithm. Genetic Algorithm (GA) is the heuristic algorithm that operates on the population of solution and applies the principle of survival of fittest to provide better approximation to solution. In this research a combinational circuit is designed using Cartesian Genetic Programming (CGP) and is applied to three GA`s namely: HsClone, Roulette and Compact which is tested for fitness. After the required fitness is obtained, all the algorithms are compared for generational fitness and other allied aspects. Finally the better algorithm is found out so that it can operate on the spacecraft to recover from Single Event Upsets which occurs mainly due to unpredictable hostile environment conditions.</p>
    <footer>
      <p>Special Thanks to <a style="color: white" href="#">Sanjana S</a> and <a style="color: white" href="https://www.cv.tu-berlin.de/menue/mitarbeiter/hardik_jain/">Hardik Jain </a> &copy; 2020</p>
    </footer>
  </body>
</html>
